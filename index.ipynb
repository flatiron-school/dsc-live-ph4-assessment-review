{"cells": [{"cell_type": "markdown", "metadata": {"index": 0}, "source": ["# Phase 4 Code Challenge Review"]}, {"cell_type": "markdown", "metadata": {"index": 1}, "source": ["TOC:\n", "\n", "  - [PCA](#pca)\n", "  - [NLP](#nlp)\n", "  - [Time Series](#ts)  \n", "  - [Clustering](#clust)\n"]}, {"cell_type": "markdown", "metadata": {"index": 2}, "source": ["<a id='pca'></a>"]}, {"cell_type": "markdown", "metadata": {"index": 3}, "source": ["# PCA"]}, {"cell_type": "markdown", "metadata": {"index": 4}, "source": ["When creating principle components, PCA aims to find a vectors in the direction of our feature space that is fit to what?"]}, {"cell_type": "markdown", "metadata": {"index": 5}, "source": ["Principal Component Analysis creates a set of features called principal compenents. This reduces the dimensions of our data set from the original `n` components.  The components are built successively.  Describe what the first principal component represents in relation to the original feature set."]}, {"cell_type": "markdown", "metadata": {"index": 6}, "source": ["> Your answer here"]}, {"cell_type": "markdown", "metadata": {"index": "Placeholder"}, "source": ["*YOUR ANSWER HERE*"]}, {"cell_type": "markdown", "metadata": {"index": 8}, "source": ["Why is scaling important for PCA?"]}, {"cell_type": "markdown", "metadata": {"index": 9}, "source": ["> Your answer here"]}, {"cell_type": "markdown", "metadata": {"index": "Placeholder"}, "source": ["*YOUR ANSWER HERE*"]}, {"cell_type": "markdown", "metadata": {"index": 11}, "source": ["What are some reasons for using PCA?\n"]}, {"cell_type": "markdown", "metadata": {"index": 12}, "source": ["> Your answer here"]}, {"cell_type": "markdown", "metadata": {"index": "Placeholder"}, "source": ["*YOUR ANSWER HERE*"]}, {"cell_type": "markdown", "metadata": {"index": 14}, "source": ["How can one determine how many principle components to use in a model?"]}, {"cell_type": "markdown", "metadata": {"index": 15}, "source": ["> Your answer here"]}, {"cell_type": "markdown", "metadata": {"index": 16}, "source": ["# Now let's implement PCA in code."]}, {"cell_type": "code", "execution_count": null, "metadata": {"index": 17}, "outputs": [], "source": ["import pandas as pd\n", "from sklearn.datasets import  load_breast_cancer\n", "data = load_breast_cancer()\n", "X = pd.DataFrame(data['data'], columns = data['feature_names'])\n", "X.head()"]}, {"cell_type": "code", "execution_count": null, "metadata": {"index": 18}, "outputs": [], "source": ["# appropriately preprocess X"]}, {"cell_type": "code", "execution_count": null, "metadata": {"index": 19}, "outputs": [], "source": ["# instantiate a pca object with 2 components"]}, {"cell_type": "code", "execution_count": null, "metadata": {"index": 20}, "outputs": [], "source": ["# determine how much of the total variance is explained by the first two components"]}, {"cell_type": "markdown", "metadata": {"index": 21}, "source": ["<a id='nlp'></a>\n"]}, {"cell_type": "markdown", "metadata": {"index": 22}, "source": ["# NLP"]}, {"cell_type": "markdown", "metadata": {"index": 23}, "source": ["For NLP data, what is the entire data of records called?"]}, {"cell_type": "markdown", "metadata": {"index": 24}, "source": ["> your answer here"]}, {"cell_type": "markdown", "metadata": {"index": 25}, "source": ["What is an individual record called?"]}, {"cell_type": "markdown", "metadata": {"index": 26}, "source": ["> your answer here"]}, {"cell_type": "markdown", "metadata": {"index": 27}, "source": ["What is a group of two words that appear next to one-another in a document?"]}, {"cell_type": "markdown", "metadata": {"index": 28}, "source": ["> Your answer here"]}, {"cell_type": "markdown", "metadata": {"index": 29}, "source": ["What is a high frequency, semantically low value word called? "]}, {"cell_type": "markdown", "metadata": {"index": 30}, "source": ["> Your answer here"]}, {"cell_type": "markdown", "metadata": {"index": 31}, "source": ["List the preprocessing steps we can employ to create a cleaner feature set to our models."]}, {"cell_type": "markdown", "metadata": {"index": 32}, "source": ["> Your answer here"]}, {"cell_type": "markdown", "metadata": {"index": 33}, "source": ["Explain the difference between the two main vectorizors we employ to transform the data into the document-term matrix."]}, {"cell_type": "markdown", "metadata": {"index": 34}, "source": ["> Your answer here"]}, {"cell_type": "markdown", "metadata": {"index": 35}, "source": ["# NLP Code"]}, {"cell_type": "code", "execution_count": null, "metadata": {"index": 36}, "outputs": [], "source": ["# data import\n", "policies = pd.read_csv('data/2020_policies_feb_24.csv')\n", "\n", "def warren_not_warren(label):\n", "    \n", "    '''Make label a binary between Elizabeth Warren\n", "    speeches and speeches from all other candidates'''\n", "    \n", "    if label =='warren':\n", "        return 1\n", "    else:\n", "        return 0\n", "    \n", "policies['candidate'] = policies['candidate'].apply(warren_not_warren)\n", "\n", "policies.head()"]}, {"cell_type": "code", "execution_count": null, "metadata": {"index": 37}, "outputs": [], "source": ["# split into train and test set \n", "# note: for demonstration purposes, we will not use cross-validation here nor a holdout set."]}, {"cell_type": "code", "execution_count": null, "metadata": {"index": 38}, "outputs": [], "source": ["# Import and instantiate a Count Vectorizer with defaults"]}, {"cell_type": "code", "execution_count": null, "metadata": {"index": 39}, "outputs": [], "source": ["# Transform train and test sets with the Count Vectorizer\n", "# then fit a logistic regression model on it."]}, {"cell_type": "code", "execution_count": null, "metadata": {"index": 40}, "outputs": [], "source": ["# Score on both train and test sets."]}, {"cell_type": "code", "execution_count": null, "metadata": {"index": 41}, "outputs": [], "source": ["# Tune some hyperparameters of the vectorizer and assess the performance"]}, {"cell_type": "markdown", "metadata": {"index": 42}, "source": ["<a id='ts'></a>"]}, {"cell_type": "markdown", "metadata": {"index": 43}, "source": ["# Time Series"]}, {"cell_type": "code", "execution_count": null, "metadata": {"index": 44}, "outputs": [], "source": ["import pandas as pd\n", "import numpy as np"]}, {"cell_type": "code", "execution_count": null, "metadata": {"index": 45}, "outputs": [], "source": ["ap = pd.read_csv('data/AirPassengers.csv')"]}, {"cell_type": "markdown", "metadata": {"index": 46}, "source": ["With the data above, what is the first step in transforming it into data suitable for our time series models?"]}, {"cell_type": "markdown", "metadata": {"index": 47}, "source": ["> Your answer here"]}, {"cell_type": "code", "execution_count": null, "metadata": {"index": 48}, "outputs": [], "source": ["# Perform that step in code"]}, {"cell_type": "markdown", "metadata": {"index": 49}, "source": ["What types of patterns might we expect to find in our time series datasets?"]}, {"cell_type": "code", "execution_count": null, "metadata": {"index": 50}, "outputs": [], "source": ["# plot the time series"]}, {"cell_type": "markdown", "metadata": {"index": 51}, "source": ["What type of patterns do you see in the above plot?"]}, {"cell_type": "markdown", "metadata": {"index": 52}, "source": ["> Your answer here"]}, {"cell_type": "code", "execution_count": null, "metadata": {"index": 53}, "outputs": [], "source": ["# Add to the plot to visualize patterns by looking at summary statistics across a window of time."]}, {"cell_type": "markdown", "metadata": {"index": 54}, "source": ["What are some ways to remove those trends? "]}, {"cell_type": "markdown", "metadata": {"index": 55}, "source": ["What is the goal of removing those trends?"]}, {"cell_type": "markdown", "metadata": {"index": 56}, "source": ["> Your answer here"]}, {"cell_type": "code", "execution_count": null, "metadata": {"index": 57}, "outputs": [], "source": ["# Attempt to make the series stationary using differencing"]}, {"cell_type": "markdown", "metadata": {"index": 58}, "source": ["How can we diagnose whether we have successfully removed the trends?"]}, {"cell_type": "markdown", "metadata": {"index": 59}, "source": ["> Your answer here"]}, {"cell_type": "markdown", "metadata": {"index": 60}, "source": ["Use the Augmented Dickey Fuller test to see if the detrended data is ready for modeling"]}, {"cell_type": "code", "execution_count": null, "metadata": {"index": 61}, "outputs": [], "source": ["# your code here"]}, {"cell_type": "markdown", "metadata": {"index": 62}, "source": ["<a id='clust'></a>"]}, {"cell_type": "markdown", "metadata": {"index": 63}, "source": ["# Clustering"]}, {"cell_type": "markdown", "metadata": {"index": 64}, "source": ["Question: What is the difference between supervised and unsupervised learning?"]}, {"cell_type": "markdown", "metadata": {"index": 65}, "source": ["> Your answer here"]}, {"cell_type": "markdown", "metadata": {"index": 66}, "source": ["Describe how the kmeans algorithm updates its cluster centers after initialization."]}, {"cell_type": "markdown", "metadata": {"index": 67}, "source": ["> Your answer here"]}, {"cell_type": "markdown", "metadata": {"index": 68}, "source": ["What is inertia, and how does kmeans use inertia to determine the best estimator?"]}, {"cell_type": "markdown", "metadata": {"index": 69}, "source": ["> Your answer here"]}, {"cell_type": "code", "execution_count": null, "metadata": {"index": 70}, "outputs": [], "source": ["from sklearn.cluster import KMeans\n", "\n", "KMeans()"]}, {"cell_type": "markdown", "metadata": {"index": 71}, "source": ["What other metric do we have to score the clusters which are formed?"]}, {"cell_type": "markdown", "metadata": {"index": 72}, "source": ["Describe the difference between it and inertia."]}, {"cell_type": "markdown", "metadata": {"index": 73}, "source": ["> Your answer here"]}, {"cell_type": "markdown", "metadata": {"index": 74}, "source": ["# Code Cluster Practice with Heirarchical Agglomerative Clustering"]}, {"cell_type": "markdown", "metadata": {"index": 75}, "source": ["After the above conceptual review of KMeans, let's practice coding with agglomerative clustering."]}, {"cell_type": "code", "execution_count": null, "metadata": {"index": 76}, "outputs": [], "source": ["from sklearn.datasets import load_iris\n", "\n", "data = load_iris()\n", "X = pd.DataFrame(data['data'])\n", "y = data['target']"]}, {"cell_type": "code", "execution_count": null, "metadata": {"index": 77}, "outputs": [], "source": ["# Import the relevent clusterer and instantiate an instance of it. \n", "# Indicate the number of clusters you want"]}, {"cell_type": "code", "execution_count": null, "metadata": {"index": 78}, "outputs": [], "source": ["# Preprocess the data"]}, {"cell_type": "code", "execution_count": null, "metadata": {"index": 79}, "outputs": [], "source": ["# Fit the object"]}, {"cell_type": "code", "execution_count": null, "metadata": {"index": 80}, "outputs": [], "source": ["# Calculate a silhouette score"]}, {"cell_type": "code", "execution_count": null, "metadata": {"index": 81}, "outputs": [], "source": ["# Repeat with another choice for number of clusters"]}, {"cell_type": "code", "execution_count": null, "metadata": {"index": 82}, "outputs": [], "source": ["# Determine which is a better number"]}, {"cell_type": "markdown", "metadata": {"index": 83}, "source": ["# Bonus: Use PCA to visualize in two dimensions the cluster groups of the best metric."]}, {"cell_type": "code", "execution_count": null, "metadata": {"index": 84}, "outputs": [], "source": ["# your code here"]}], "metadata": {"kernelspec": {"display_name": "learn-env", "language": "python", "name": "learn-env"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.7.3"}}, "nbformat": 4, "nbformat_minor": 4}